{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO models\n",
    "# plate_detector = YOLO(\"best.pt\")  # License plate detection model\n",
    "# char_recognizer = YOLO(\"model-m/weights/best.pt\")  # Character recognition model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_detector = YOLO(\"model-s-detection/best.pt\")  # License plate detection model\n",
    "char_recognizer = YOLO(\"model-s-ocr/best.pt\")  # Character recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character Mapping\n",
    "char_map = {\n",
    "    0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9',\n",
    "    10: 'Metro', 11: 'A', 12: 'Bha', 13: 'Cha', 14: 'Chha', 15: 'Da', 16: 'DA', 17: 'E',\n",
    "    18: 'Ga', 19: 'Gha', 20: 'Ha', 21: 'Ja', 22: 'Jha', 23: 'Ka', 24: 'Kha', 25: 'La',\n",
    "    26: 'Ma', 27: 'Na', 28: 'Pa', 29: 'Sa', 30: 'Sha', 31: 'Ta', 32: 'THA', 33: 'Tha',\n",
    "    34: 'U', 35: 'Bagerhat', 36: 'Bagura', 37: 'Bandarban', 38: 'Barguna', 39: 'Barisal',\n",
    "    40: 'Bhola', 41: 'Brahmanbaria', 42: 'Chandpur', 43: 'Chapainawabganj', 44: 'Chatto',\n",
    "    45: 'Chattogram', 46: 'Chuadanga', 47: 'Coxs Bazar', 48: 'Cumilla', 49: 'Dhaka',\n",
    "    50: 'Dinajpur', 51: 'Faridpur', 52: 'Feni', 53: 'Gaibandha', 54: 'Gazipur',\n",
    "    55: 'Gopalganj', 56: 'Habiganj', 57: 'Jamalpur', 58: 'Jessore', 59: 'Jhalokati',\n",
    "    60: 'Jhenaidah', 61: 'Joypurhat', 62: 'Khagrachari', 63: 'Khulna', 64: 'Kishoreganj',\n",
    "    65: 'Kurigram', 66: 'Kustia', 67: 'Lakshmipur', 68: 'Lalmonirhat', 69: 'Madaripur',\n",
    "    70: 'Magura', 71: 'Manikganj', 72: 'Meherpur', 73: 'Moulvibazar', 74: 'Mymensingh',\n",
    "    75: 'Naogaon', 76: 'Narail', 77: 'Narayanganj', 78: 'Narsingdi', 79: 'Natore',\n",
    "    80: 'Netrokona', 81: 'Nilphamari', 82: 'Noakhali', 83: 'Pabna', 84: 'panchagarh',\n",
    "    85: 'Patuakhali', 86: 'Pirojpur', 87: 'Raj', 88: 'Rajbari', 89: 'Rajshahi',\n",
    "    90: 'Rangamati', 91: 'Rangpur', 92: 'Satkhira', 93: 'Shariatpur', 94: 'Sherpur',\n",
    "    95: 'Sirajganj', 96: 'Sunamganj', 97: 'Sylhet', 98: 'Tangail', 99: 'Thakurgaon',\n",
    "    100: 'Dha', 101: 'Ba'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1(YoloV8m, no frame skipping,no image size reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open video stream\n",
    "#/home/avrohabib/Downloads/drive-download-20250218T081625Z-001/1.mp4\n",
    "#/home/avrohabib/Downloads/video/Video-data\n",
    "cap = cv2.VideoCapture(\"/home/avrohabib/Downloads/video/Video-data/v2.mp4\")  # Use 0 for webcam, or provide a video file path\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Exit if video ends\n",
    "\n",
    "    # Detect license plate\n",
    "    plate_results = plate_detector(frame,verbose = False)\n",
    "\n",
    "    for plate in plate_results:\n",
    "        boxes = plate.boxes.xyxy\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            plate_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "            if plate_img.size == 0:\n",
    "                continue  # Skip empty detections\n",
    "\n",
    "            # Process detected license plate\n",
    "            char_results = char_recognizer(plate_img,verbose = False)\n",
    "\n",
    "            detected_chars = []\n",
    "            for char in char_results:\n",
    "                for cbox in char.boxes:\n",
    "                    cx1, cy1, cx2, cy2 = cbox.xyxy[0]\n",
    "                    class_id = int(cbox.cls)\n",
    "                    center_x = (cx1 + cx2) / 2  # X center for sorting\n",
    "\n",
    "                    detected_chars.append((center_x, class_id))\n",
    "\n",
    "            # Separate letters and numbers\n",
    "            label1, label2 = [], []\n",
    "            for center_x, class_id in detected_chars:\n",
    "                if class_id in range(0, 10):  # Numeric characters (0-9)\n",
    "                    label2.append((center_x, class_id))\n",
    "                else:  # Non-numeric characters\n",
    "                    label1.append((center_x, class_id))\n",
    "\n",
    "            # Sort characters by X position\n",
    "            label1.sort(key=lambda x: x[0])\n",
    "            label2.sort(key=lambda x: x[0])\n",
    "\n",
    "            # Convert class IDs to text\n",
    "            sorted_text = \"\".join([char_map[c[1]] for c in label1]) + \" \" + \"\".join([char_map[c[1]] for c in label2])\n",
    "\n",
    "            # Draw bounding box around license plate\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, sorted_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Real-Time License Plate Recognition\", frame)\n",
    "\n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2(YoloV8m, frame skipping,image size reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "# # Load YOLO models\n",
    "# plate_detector = YOLO(\"best.pt\")  # License plate detection model\n",
    "# char_recognizer = YOLO(\"model-m/weights/best.pt\")  # Character recognition model\n",
    "\n",
    "\n",
    "\n",
    "# Open webcam or video file\n",
    "cap = cv2.VideoCapture(\"/home/avrohabib/Downloads/video/Video-data/v1.mp4\")  # 0 for webcam, or replace with video file path\n",
    "\n",
    "#Set higher FPS for smooth video\n",
    "# cap.set(cv2.CAP_PROP_FPS, 60)  \n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 416)  # Reduce resolution for speed\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 416)\n",
    "\n",
    "# Use GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "plate_detector.to(device)\n",
    "char_recognizer.to(device)\n",
    "\n",
    "# frame_skip = 2  # Skip every 2nd frame for speed\n",
    "# frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()  # Track FPS\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Exit if video ends\n",
    "\n",
    "    # frame_count += 1\n",
    "    # if frame_count % frame_skip != 0:\n",
    "    #     continue  # Skip frames to improve FPS\n",
    "\n",
    "    # Detect license plate\n",
    "    # plate_results = plate_detector(frame, conf=0.6, imgsz=416, verbose=False)   # Set confidence threshold\n",
    "    plate_results = plate_detector(frame,  verbose=False) \n",
    "\n",
    "    for plate in plate_results:\n",
    "        boxes = plate.boxes.xyxy\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            plate_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "            if plate_img.size == 0:\n",
    "                continue  # Skip empty detections\n",
    "\n",
    "            # Process detected license plate\n",
    "            # char_results = char_recognizer(plate_img, conf=0.6, imgsz=320, verbose=False)\n",
    "            char_results = char_recognizer(plate_img,  verbose=False)\n",
    "\n",
    "            detected_chars = []\n",
    "            for char in char_results:\n",
    "                for cbox in char.boxes:\n",
    "                    cx1, cy1, cx2, cy2 = cbox.xyxy[0]\n",
    "                    class_id = int(cbox.cls)\n",
    "                    center_x = (cx1 + cx2) / 2  # X center for sorting\n",
    "\n",
    "                    detected_chars.append((center_x, class_id))\n",
    "\n",
    "            # Separate and sort letters/numbers\n",
    "            label1, label2 = [], []\n",
    "            for center_x, class_id in detected_chars:\n",
    "                if class_id in range(0, 10):  # Numeric characters\n",
    "                    label2.append((center_x, class_id))\n",
    "                else:  # Letters\n",
    "                    label1.append((center_x, class_id))\n",
    "\n",
    "            label1.sort(key=lambda x: x[0])  # Sort letters\n",
    "            label2.sort(key=lambda x: x[0])  # Sort numbers\n",
    "\n",
    "            # Convert class IDs to text\n",
    "            sorted_text = \"\".join([char_map[c[1]] for c in label1]) + \" \" + \"\".join([char_map[c[1]] for c in label2])\n",
    "\n",
    "            # Draw bounding box and text\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, sorted_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    # Calculate and display FPS\n",
    "    fps = 1 / (time.time() - start_time)\n",
    "    cv2.putText(frame, f'FPS: {int(fps)}', (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Show processed video\n",
    "    cv2.imshow(\"Real-Time License Plate Recognition\", frame)\n",
    "\n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3(YoloV8n, no frame skipping,no image size reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open video stream\n",
    "#/home/avrohabib/Downloads/drive-download-20250218T081625Z-001/1.mp4\n",
    "#/home/avrohabib/Downloads/video/Video-data\n",
    "plate_detector = YOLO(\"model-n-detection/best.pt\")  # License plate detection model\n",
    "char_recognizer = YOLO(\"model-n-ocr/best.pt\")  # Character recognition model\n",
    "cap = cv2.VideoCapture(\"/home/avrohabib/Downloads/video/Video-data/v1.mp4\")  # Use 0 for webcam, or provide a video file path\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Exit if video ends\n",
    "\n",
    "    # Detect license plate\n",
    "    plate_results = plate_detector(frame,verbose = False)\n",
    "\n",
    "    for plate in plate_results:\n",
    "        boxes = plate.boxes.xyxy\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            plate_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "            if plate_img.size == 0:\n",
    "                continue  # Skip empty detections\n",
    "\n",
    "            # Process detected license plate\n",
    "            char_results = char_recognizer(plate_img,verbose = False)\n",
    "\n",
    "            detected_chars = []\n",
    "            for char in char_results:\n",
    "                for cbox in char.boxes:\n",
    "                    cx1, cy1, cx2, cy2 = cbox.xyxy[0]\n",
    "                    class_id = int(cbox.cls)\n",
    "                    center_x = (cx1 + cx2) / 2  # X center for sorting\n",
    "\n",
    "                    detected_chars.append((center_x, class_id))\n",
    "\n",
    "            # Separate letters and numbers\n",
    "            label1, label2 = [], []\n",
    "            for center_x, class_id in detected_chars:\n",
    "                if class_id in range(0, 10):  # Numeric characters (0-9)\n",
    "                    label2.append((center_x, class_id))\n",
    "                else:  # Non-numeric characters\n",
    "                    label1.append((center_x, class_id))\n",
    "\n",
    "            # Sort characters by X position\n",
    "            label1.sort(key=lambda x: x[0])\n",
    "            label2.sort(key=lambda x: x[0])\n",
    "\n",
    "            # Convert class IDs to text\n",
    "            sorted_text = \"\".join([char_map[c[1]] for c in label1]) + \" \" + \"\".join([char_map[c[1]] for c in label2])\n",
    "\n",
    "            # Draw bounding box around license plate\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, sorted_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Real-Time License Plate Recognition\", frame)\n",
    "\n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3(YoloV8n, frame skipping,image size reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "# # Load YOLO models\n",
    "# plate_detector = YOLO(\"best.pt\")  # License plate detection model\n",
    "# char_recognizer = YOLO(\"model-m/weights/best.pt\")  # Character recognition model\n",
    "\n",
    "\n",
    "\n",
    "# Open webcam or video file\n",
    "cap = cv2.VideoCapture(\"/home/avrohabib/Downloads/video/Video-data/v1.mp4\")  # 0 for webcam, or replace with video file path\n",
    "\n",
    "#Set higher FPS for smooth video\n",
    "# cap.set(cv2.CAP_PROP_FPS, 60)  \n",
    "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 416)  # Reduce resolution for speed\n",
    "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 416)\n",
    "\n",
    "# Use GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "plate_detector.to(device)\n",
    "char_recognizer.to(device)\n",
    "\n",
    "# frame_skip = 2  # Skip every 2nd frame for speed\n",
    "# frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()  # Track FPS\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Exit if video ends\n",
    "\n",
    "    # frame_count += 1\n",
    "    # if frame_count % frame_skip != 0:\n",
    "    #     continue  # Skip frames to improve FPS\n",
    "\n",
    "    # Detect license plate\n",
    "    plate_results = plate_detector(frame, conf=0.25, imgsz=640, verbose=False)   # Set confidence threshold\n",
    "    # plate_results = plate_detector(frame,  verbose=False) \n",
    "\n",
    "    for plate in plate_results:\n",
    "        boxes = plate.boxes.xyxy\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            plate_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "            if plate_img.size == 0:\n",
    "                continue  # Skip empty detections\n",
    "\n",
    "            # Process detected license plate\n",
    "            char_results = char_recognizer(plate_img, conf=0.25, imgsz=416, verbose=False)\n",
    "            # char_results = char_recognizer(plate_img,  verbose=False)\n",
    "\n",
    "            detected_chars = []\n",
    "            for char in char_results:\n",
    "                for cbox in char.boxes:\n",
    "                    cx1, cy1, cx2, cy2 = cbox.xyxy[0]\n",
    "                    class_id = int(cbox.cls)\n",
    "                    center_x = (cx1 + cx2) / 2  # X center for sorting\n",
    "\n",
    "                    detected_chars.append((center_x, class_id))\n",
    "\n",
    "            # Separate and sort letters/numbers\n",
    "            label1, label2 = [], []\n",
    "            for center_x, class_id in detected_chars:\n",
    "                if class_id in range(0, 10):  # Numeric characters\n",
    "                    label2.append((center_x, class_id))\n",
    "                else:  # Letters\n",
    "                    label1.append((center_x, class_id))\n",
    "\n",
    "            label1.sort(key=lambda x: x[0])  # Sort letters\n",
    "            label2.sort(key=lambda x: x[0])  # Sort numbers\n",
    "\n",
    "            # Convert class IDs to text\n",
    "            sorted_text = \"\".join([char_map[c[1]] for c in label1]) + \" \" + \"\".join([char_map[c[1]] for c in label2])\n",
    "\n",
    "            # Draw bounding box and text\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, sorted_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    # Calculate and display FPS\n",
    "    fps = 1 / (time.time() - start_time)\n",
    "    cv2.putText(frame, f'FPS: {int(fps)}', (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Show processed video\n",
    "    cv2.imshow(\"Real-Time License Plate Recognition\", frame)\n",
    "\n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3 (Shitt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import threading\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLO models (Ensure they run on GPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "plate_detector = YOLO(\"best.pt\").to(device).eval().half()\n",
    "char_recognizer = YOLO(\"model-m/weights/best.pt\").to(device).eval().half()\n",
    "\n",
    "\n",
    "\n",
    "# Capture video with threading\n",
    "cap = cv2.VideoCapture(\"/home/avrohabib/Downloads/video/Video-data/v1.mp4\")\n",
    "cap.set(cv2.CAP_PROP_FPS, 60)  # High FPS input\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Adjusted for speed\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "frame = None\n",
    "running = True\n",
    "lock = threading.Lock()\n",
    "\n",
    "def capture_frames():\n",
    "    global frame, running\n",
    "    while running:\n",
    "        ret, temp_frame = cap.read()\n",
    "        if ret:\n",
    "            with lock:\n",
    "                frame = temp_frame\n",
    "\n",
    "# Start capture thread\n",
    "threading.Thread(target=capture_frames, daemon=True).start()\n",
    "\n",
    "frame_skip = 2  # Skip frames dynamically\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    with lock:\n",
    "        if frame is None:\n",
    "            continue  # Skip empty frames\n",
    "        current_frame = frame.copy()\n",
    "\n",
    "    start_time = time.time()\n",
    "    frame_count += 1\n",
    "\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue  # Skip frames to increase FPS\n",
    "\n",
    "    # Detect license plate\n",
    "    plate_results = plate_detector(current_frame, conf=0.6, imgsz=416, verbose=False)\n",
    "\n",
    "    for plate in plate_results:\n",
    "        for box in plate.boxes.xyxy:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            plate_img = current_frame[y1:y2, x1:x2]\n",
    "\n",
    "            if plate_img.size == 0:\n",
    "                continue  # Avoid errors\n",
    "\n",
    "            # Detect characters in the plate\n",
    "            char_results = char_recognizer(plate_img, conf=0.6, imgsz=320, verbose=False)\n",
    "\n",
    "            detected_chars = []\n",
    "            for char in char_results:\n",
    "                for cbox in char.boxes:\n",
    "                    cx1, cy1, cx2, cy2 = cbox.xyxy[0]\n",
    "                    class_id = int(cbox.cls)\n",
    "                    center_x = (cx1 + cx2) / 2  # X center for sorting\n",
    "                    detected_chars.append((center_x, class_id))\n",
    "\n",
    "            # Sort characters left to right\n",
    "            detected_chars.sort(key=lambda x: x[0])\n",
    "\n",
    "            # Convert class IDs to text\n",
    "            plate_text = \"\".join([char_map[c[1]] for c in detected_chars])\n",
    "\n",
    "            # Draw bounding box & text\n",
    "            cv2.rectangle(current_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(current_frame, plate_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    # Calculate FPS\n",
    "    fps = 1 / (time.time() - start_time)\n",
    "    cv2.putText(current_frame, f'FPS: {int(fps)}', (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Adjust frame skipping dynamically\n",
    "    if fps < 15: \n",
    "        frame_skip = 3  # Skip more frames if slow\n",
    "    elif fps > 30: \n",
    "        frame_skip = 1  # Process every frame if fast\n",
    "\n",
    "    # Show output\n",
    "    cv2.imshow(\"Real-Time License Plate Recognition\", current_frame)\n",
    "\n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        running = False\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying a multithread approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m reader_thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     70\u001b[0m processor_thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 72\u001b[0m \u001b[43mreader_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m processor_thread\u001b[38;5;241m.\u001b[39mjoin()\n",
      "File \u001b[0;32m/usr/lib64/python3.12/threading.py:1149\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1149\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib64/python3.12/threading.py:1169\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1170\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "def frame_reader(cap, frame_queue):\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_queue.put(frame)\n",
    "    cap.release()\n",
    "\n",
    "def process_frames(frame_queue):\n",
    "    while True:\n",
    "        if frame_queue.empty():\n",
    "            continue\n",
    "        frame = frame_queue.get()\n",
    "        \n",
    "        plate_results = plate_detector(frame, verbose=False)\n",
    "\n",
    "        for plate in plate_results:\n",
    "            boxes = plate.boxes.xyxy\n",
    "\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                plate_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "                if plate_img.size == 0:\n",
    "                    continue\n",
    "\n",
    "                char_results = char_recognizer(plate_img, verbose=False)\n",
    "\n",
    "                detected_chars = []\n",
    "                for char in char_results:\n",
    "                    for cbox in char.boxes:\n",
    "                        cx1, cy1, cx2, cy2 = cbox.xyxy[0]\n",
    "                        class_id = int(cbox.cls)\n",
    "                        center_x = (cx1 + cx2) / 2\n",
    "                        detected_chars.append((center_x, class_id))\n",
    "\n",
    "                label1, label2 = [], []\n",
    "                for center_x, class_id in detected_chars:\n",
    "                    if class_id in range(0, 10):\n",
    "                        label2.append((center_x, class_id))\n",
    "                    else:\n",
    "                        label1.append((center_x, class_id))\n",
    "\n",
    "                label1.sort(key=lambda x: x[0])\n",
    "                label2.sort(key=lambda x: x[0])\n",
    "\n",
    "                sorted_text = \"\".join([char_map[c[1]] for c in label1]) + \" \" + \"\".join([char_map[c[1]] for c in label2])\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, sorted_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.imshow(\"Real-Time License Plate Recognition\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Initialize video capture and frame queue\n",
    "cap = cv2.VideoCapture(\"/home/avrohabib/Downloads/video/Video-data/v2.mp4\")\n",
    "frame_queue = queue.Queue(maxsize=10)\n",
    "\n",
    "# Start threads\n",
    "reader_thread = threading.Thread(target=frame_reader, args=(cap, frame_queue))\n",
    "processor_thread = threading.Thread(target=process_frames, args=(frame_queue,))\n",
    "\n",
    "reader_thread.start()\n",
    "processor_thread.start()\n",
    "\n",
    "reader_thread.join()\n",
    "processor_thread.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
